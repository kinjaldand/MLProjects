{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Data from external sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.datasets.base.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "print(type(iris))\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fnHandleMsg(msg,msgType=\"\"):\n",
    "    print(msg)\n",
    "\n",
    "\n",
    "def fnAssignColnames(df,colNames=None):\n",
    "    if colNames is not None and len(colNames)==len(df.columns):\n",
    "        df.columns=colNames\n",
    "\n",
    "    return df\n",
    "\n",
    "    \n",
    "    \n",
    "def fnCreatePdFrameFromArray(arrayTuple,colNames=None):\n",
    "    #return pd.DataFrame(np.column_stack(arrayTuple))\n",
    "    df=None\n",
    "    for a in arrayTuple:\n",
    "        if len(a.shape)==1:\n",
    "            n=pd.Series(a)\n",
    "        else:\n",
    "            n=pd.DataFrame(a)\n",
    "        if df is None:\n",
    "            df=pd.DataFrame(n)\n",
    "        else:\n",
    "            df=pd.concat([df,n],axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def fnGetDf(data,colNames=None):\n",
    "    df=fnCreatePdFrameFromArray(data,colNames)\n",
    "    df=fnAssignColnames(df,colNames)\n",
    "    return df\n",
    "                        \n",
    "def fnFilterMissingValues(df):\n",
    "    missingValues=df.isnull().sum(axis=1)\n",
    "    missingValuesCount=sum(missingValues>0)\n",
    "    fnHandleMsg(\"No. of Missing Values in DF : \"+str(missingValuesCount))\n",
    "    df=df.dropna()\n",
    "    return df,missingValuesCount\n",
    "\n",
    "def fnGetUniqueValLenColumns(df):\n",
    "    iDfLen=len(df)\n",
    "    lUniqueValCount=[]\n",
    "    for col in df.columns:\n",
    "        iUniqueValLen=len(np.unique(df[col]))\n",
    "        lUniqueValCount.append(iUniqueValLen)\n",
    "        \n",
    "    return lUniqueValCount\n",
    "\n",
    "\n",
    "def fnNormalizeCols(df,colNames):\n",
    "    fnHandleMsg(\"Normalizing Values in DF for columns: \"+str(colNames))\n",
    "    from sklearn import preprocessing\n",
    "    dfNew = pd.DataFrame(df[colNames])\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    np_scaled = min_max_scaler.fit_transform(dfNew)\n",
    "    df_normalized = pd.DataFrame(np_scaled)\n",
    "    df_normalized.columns=colNames\n",
    "    df[colNames]=df_normalized\n",
    "    #for col in colNames:\n",
    "        #df[col]=df_normalized[col]\n",
    "        \n",
    "    return df\n",
    "\n",
    "def fnPlotCols(df,colNames=None,num_bins=50):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    if colNames is None:\n",
    "        colNames=df.columns\n",
    "        \n",
    "    for colName in colNames:\n",
    "        colData=df[colName]\n",
    "        fnPlotHistogram(colData,colName)\n",
    "        fnPlotBoxplot(colData,colName)\n",
    "        \n",
    "\n",
    "def fnPlotHistogram(colData,colName,num_bins=50):\n",
    "    mu=np.mean(colData)\n",
    "    sigma=np.std(colData)\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # the histogram of the data\n",
    "    n, bins, patches = ax.hist(colData, num_bins, normed=True)\n",
    "\n",
    "    # add a 'best fit' line\n",
    "    y = ((1 / (np.sqrt(2 * np.pi) * sigma)) *np.exp(-0.5 * (1 / sigma * (bins - mu))**2))\n",
    "    ax.plot(bins, y, '--')\n",
    "    ax.set_xlabel('Smarts')\n",
    "    ax.set_ylabel('Probability density')\n",
    "    ax.set_title(r'Histogram of {0}: mu={1}, sigma={2}'.format(colName,mu,sigma))\n",
    "\n",
    "    # Tweak spacing to prevent clipping of ylabel\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def fnPlotBoxplot(colData,colName):\n",
    "    colData=df[colName]\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.set_title(r'Box Plot of {0}'.format(colName))\n",
    "    ax1.boxplot(colData)\n",
    "\n",
    "    # Tweak spacing to prevent clipping of ylabel\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def RandomizeDF(df,seed=300):    \n",
    "    np.random.seed(seed)\n",
    "    perm = np.random.permutation(df.index)\n",
    "    df=df.loc[perm]\n",
    "    df.reset_index(inplace=True)\n",
    "    return df\n",
    "\n",
    "def GetXyDf(df,outputVarName):\n",
    "    y=df[outputVarName]\n",
    "    X=df.loc[:, df.columns != outputVarName]\n",
    "    return X,y\n",
    "    \n",
    "    \n",
    "    \n",
    "def GetTrainTest(df,outputVarName,testPer=0.2,seed=200):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X,y=GetXyDf(df,outputVarName)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    stratify=y, \n",
    "                                                    test_size=testPer)\n",
    "    \n",
    "    X_train.reset_index(inplace=True,drop=True)\n",
    "    X_test.reset_index(inplace=True,drop=True)\n",
    "    y_train.reset_index(inplace=True,drop=True)\n",
    "    y_test.reset_index(inplace=True,drop=True)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    \n",
    "    \n",
    "def GetkFoldedTrainVal(X,y,nFolds=5,randomstate=300):    \n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=nFolds)\n",
    "    \n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "        y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "        yield X_train, X_test ,y_train, y_test\n",
    "            \n",
    "            \n",
    "def GetScores(actualY,Pred,categoriesNames):\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.metrics import f1_score\n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    from sklearn.metrics import classification_report\n",
    "    acc_score=accuracy_score(actualY, Pred,normalize=True)\n",
    "    target_names = categoriesNames\n",
    "    f1score=classification_report(actualY, Pred, target_names=target_names)\n",
    "    cnf_matrix = confusion_matrix(actualY, Pred)\n",
    "    return acc_score,f1score,cnf_matrix\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Data into Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    SL   SH   PL   PH  fType\n",
      "0  5.1  3.5  1.4  0.2      0\n",
      "1  4.9  3.0  1.4  0.2      0\n",
      "2  4.7  3.2  1.3  0.2      0\n",
      "3  4.6  3.1  1.5  0.2      0\n",
      "4  5.0  3.6  1.4  0.2      0\n"
     ]
    }
   ],
   "source": [
    "outputVarName='fType'\n",
    "df=fnGetDf((X,y),(\"SL\",\"SH\",\"PL\",\"PH\",outputVarName))\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataSet Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               SL          SH          PL          PH       fType\n",
      "count  150.000000  150.000000  150.000000  150.000000  150.000000\n",
      "mean     5.843333    3.054000    3.758667    1.198667    1.000000\n",
      "std      0.828066    0.433594    1.764420    0.763161    0.819232\n",
      "min      4.300000    2.000000    1.000000    0.100000    0.000000\n",
      "25%      5.100000    2.800000    1.600000    0.300000    0.000000\n",
      "50%      5.800000    3.000000    4.350000    1.300000    1.000000\n",
      "75%      6.400000    3.300000    5.100000    1.800000    2.000000\n",
      "max      7.900000    4.400000    6.900000    2.500000    2.000000\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Missing Values in DF : 0\n"
     ]
    }
   ],
   "source": [
    "df,missingValuesCount=fnFilterMissingValues(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(35, dtype('float64')), (23, dtype('float64')), (43, dtype('float64')), (22, dtype('float64')), (3, dtype('int32'))]\n"
     ]
    }
   ],
   "source": [
    "lUniqueValCount=fnGetUniqueValLenColumns(df)\n",
    "print(list(zip(lUniqueValCount,df.dtypes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               SL          SH          PL          PH       fType\n",
      "count  150.000000  150.000000  150.000000  150.000000  150.000000\n",
      "mean     5.843333    3.054000    3.758667    1.198667    1.000000\n",
      "std      0.828066    0.433594    1.764420    0.763161    0.819232\n",
      "min      4.300000    2.000000    1.000000    0.100000    0.000000\n",
      "25%      5.100000    2.800000    1.600000    0.300000    0.000000\n",
      "50%      5.800000    3.000000    4.350000    1.300000    1.000000\n",
      "75%      6.400000    3.300000    5.100000    1.800000    2.000000\n",
      "max      7.900000    4.400000    6.900000    2.500000    2.000000\n",
      "Normalizing Values in DF for columns: ['SH', 'SL', 'PL', 'PH']\n",
      "               SL          SH          PL          PH       fType\n",
      "count  150.000000  150.000000  150.000000  150.000000  150.000000\n",
      "mean     0.428704    0.439167    0.467571    0.457778    1.000000\n",
      "std      0.230018    0.180664    0.299054    0.317984    0.819232\n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000\n",
      "25%      0.222222    0.333333    0.101695    0.083333    0.000000\n",
      "50%      0.416667    0.416667    0.567797    0.500000    1.000000\n",
      "75%      0.583333    0.541667    0.694915    0.708333    2.000000\n",
      "max      1.000000    1.000000    1.000000    1.000000    2.000000\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())\n",
    "colNames=[\"SH\",\"SL\",\"PL\",\"PH\"]\n",
    "df=fnNormalizeCols(df,colNames)\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fnPlotCols(df,colNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    50\n",
      "1    50\n",
      "0    50\n",
      "Name: fType, dtype: int64\n",
      "2    40\n",
      "1    40\n",
      "0    40\n",
      "Name: fType, dtype: int64\n",
      "2    10\n",
      "1    10\n",
      "0    10\n",
      "Name: fType, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[outputVarName].value_counts())\n",
    "X_trainVal, X_test, y_trainVal, y_test=GetTrainTest(df,outputVarName)\n",
    "print(y_trainVal.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         8\n",
      "          1       0.78      0.88      0.82         8\n",
      "          2       0.86      0.75      0.80         8\n",
      "\n",
      "avg / total       0.88      0.88      0.87        24\n",
      " [[8 0 0]\n",
      " [0 7 1]\n",
      " [0 2 6]]\n",
      "0.9583333333333334              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         8\n",
      "          1       1.00      0.88      0.93         8\n",
      "          2       0.89      1.00      0.94         8\n",
      "\n",
      "avg / total       0.96      0.96      0.96        24\n",
      " [[8 0 0]\n",
      " [0 7 1]\n",
      " [0 0 8]]\n",
      "0.9166666666666666              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         8\n",
      "          1       1.00      0.75      0.86         8\n",
      "          2       0.80      1.00      0.89         8\n",
      "\n",
      "avg / total       0.93      0.92      0.92        24\n",
      " [[8 0 0]\n",
      " [0 6 2]\n",
      " [0 0 8]]\n",
      "0.8333333333333334              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         8\n",
      "          1       0.75      0.75      0.75         8\n",
      "          2       0.75      0.75      0.75         8\n",
      "\n",
      "avg / total       0.83      0.83      0.83        24\n",
      " [[8 0 0]\n",
      " [0 6 2]\n",
      " [0 2 6]]\n",
      "1.0              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00         8\n",
      "          1       1.00      1.00      1.00         8\n",
      "          2       1.00      1.00      1.00         8\n",
      "\n",
      "avg / total       1.00      1.00      1.00        24\n",
      " [[8 0 0]\n",
      " [0 8 0]\n",
      " [0 0 8]]\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "for X_train, X_val ,y_train, y_val in GetkFoldedTrainVal(X_trainVal,y_trainVal):\n",
    "    \"\"\"\n",
    "    print(len(X_train),len(X_val))\n",
    "    print(y_train.value_counts())\n",
    "    print(y_val.value_counts())\\\n",
    "    \"\"\"\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    clf = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial')\n",
    "    clf.fit(X_train, y_train)\n",
    "    predClass=clf.predict(X_val)\n",
    "    \n",
    "    categoriesNames=[str(x) for x in np.unique(y_val)]\n",
    "    acc_score,f1score,cnf_matrix=GetScores(y_val,predClass,categoriesNames)\n",
    "    results.append((acc_score,f1score,cnf_matrix))\n",
    "    print(acc_score,f1score,cnf_matrix)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy :  0.9166666666666667\n",
      "Accuracy Variance:  0.05892556509887895\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Accuracy : \",np.mean([x[0] for x in results]))\n",
    "print(\"Accuracy Variance: \",np.std([x[0] for x in results]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus the baseline accuacy for this Dataset is 91% with very slight variation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
